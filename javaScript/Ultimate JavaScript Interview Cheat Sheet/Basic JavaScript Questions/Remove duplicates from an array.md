# ðŸ’¡ **Question:** How do you remove duplicates from an array in JavaScript?

ðŸ‘‰ **Answer:**

There are multiple ways to remove duplicates from an array efficiently. Below are the most common methods:

---

### **1ï¸âƒ£ Using `Set()` (Best Performance - O(n))**

```js
function removeDuplicates(arr) {
    return [...new Set(arr)];
}

console.log(removeDuplicates([1, 2, 2, 3, 4, 4, 5])); // Output: [1, 2, 3, 4, 5]
```

ðŸ”¹ **Key Points to Mention:**

âœ” `Set` stores only unique values, automatically removing duplicates.

âœ”  **Time Complexity: O(n)** ,  **Space Complexity: O(n)** .

âœ” **Best for performance** when order doesn't matter.

---

### **2ï¸âƒ£ Using a Hash Map (Preserves Order - O(n))**

```js
function removeDuplicates(arr) {
    let uniqueElements = {};
    return arr.filter(item => !uniqueElements[item] && (uniqueElements[item] = true));
}

console.log(removeDuplicates([1, 2, 2, 3, 4, 4, 5])); // Output: [1, 2, 3, 4, 5]
```

ðŸ”¹ **Key Points to Mention:**

âœ” Uses an **object as a lookup table** to track seen values.

âœ” **Preserves original order** unlike `Set()`.

âœ”  **Time Complexity: O(n)** ,  **Space Complexity: O(n)** .

---

### **3ï¸âƒ£ Using `filter()` and `indexOf()` (O(nÂ²) - Less Efficient)**

```js
function removeDuplicates(arr) {
    return arr.filter((item, index) => arr.indexOf(item) === index);
}

console.log(removeDuplicates([1, 2, 2, 3, 4, 4, 5])); // Output: [1, 2, 3, 4, 5]
```

ðŸ”¹ **Key Points to Mention:**

âŒ Calls `indexOf()` for each element â†’ **O(nÂ²) complexity** (not ideal for large arrays).

âœ” Preserves order but  **not the most efficient** .

---

### **4ï¸âƒ£ Using `reduce()` (Preserves Order - O(n))**

```js
function removeDuplicates(arr) {
    return arr.reduce((acc, item) => {
        if (!acc.includes(item)) acc.push(item);
        return acc;
    }, []);
}

console.log(removeDuplicates([1, 2, 2, 3, 4, 4, 5])); // Output: [1, 2, 3, 4, 5]
```

ðŸ”¹ **Key Points to Mention:**

âœ” Uses `reduce()` to accumulate unique values.

âœ”  **Preserves order** , but  **`includes()` makes it O(nÂ²) in worst case** .

---

### **What to Say in the Interview:**

ðŸ—£ *"The most efficient way to remove duplicates from an array is by using a `Set()`, which provides **O(n) time complexity** and automatically ensures uniqueness. However, if preserving order is important, a hash map (`{}` or `Map()`) approach is preferred. Other methods like `filter()` with `indexOf()` or `reduce()` work but are **less efficient** for large arrays."*

ðŸ‘‰ **Final Answer:**

*"For best performance, use `new Set(arr)`, but if order matters, use a hash map."* ðŸš€
